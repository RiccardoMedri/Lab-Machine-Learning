{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJAMB2CPFcyY"
      },
      "source": [
        "# Fondamenti di Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoC4RkyCFcyZ"
      },
      "source": [
        "## Effettuiamo l'import delle librerie utilizzate nell'esercitazione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KMsq4W9-FcyZ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTjo7Pq4Fcya"
      },
      "source": [
        "Di seguito i riferimenti alle pagine di documentazione, sempre utiliti:\n",
        "\n",
        "* Rif: [pytorch](https://pytorch.org/docs/stable/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFLkUm64Fcya"
      },
      "source": [
        "Aggiungiamo alcune funzioni di utilita' per semplificare la scrittura del codice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eJW5lVDwFcya"
      },
      "outputs": [],
      "source": [
        "def info(t : torch.Tensor):\n",
        "    print(f'\\n*****')\n",
        "    print(f'Valore:\\n{t}\\n')\n",
        "    print(f'Tipo pytohn\\t: {type(t)}')\n",
        "    print(f'Tipo\\t\\t: {t.dtype}')\n",
        "    print(f'Dimensioni\\t: {t.ndim}')\n",
        "    print(f'Forma\\t\\t: {t.shape}')\n",
        "    print(f'Dispositivo\\t: {t.device}')\n",
        "    print(f'*****\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1HX92ihFcyb"
      },
      "source": [
        "## _Quando si ha a disposizione un device, e' possibile utilizzare i tensori anche al di fuori della cpu._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gVHv_P4Fcyb"
      },
      "source": [
        "Partiamo creando un tensore di esempio senza specificare altro,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k7jlJJtfFcyb"
      },
      "outputs": [],
      "source": [
        "sample_tensor = torch.tensor([[1, 2], [3, 4], [5, 6]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFWc7WeNFcyb"
      },
      "source": [
        "In questo caso il tensore stara' su cpu, verifichiamolo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAQ-ZvcPFcyb",
        "outputId": "ec460474-9e11-4fd8-e720-af639bcdd434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****\n",
            "Valore:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Tipo pytohn\t: <class 'torch.Tensor'>\n",
            "Tipo\t\t: torch.int64\n",
            "Dimensioni\t: 2\n",
            "Forma\t\t: torch.Size([3, 2])\n",
            "Dispositivo\t: cpu\n",
            "*****\n",
            "\n"
          ]
        }
      ],
      "source": [
        "info(sample_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSGzoaeSFcyb"
      },
      "source": [
        "## _Verificare la presenza del device e' il primo passo per poterlo utilizzare._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvTu9XYFcyb"
      },
      "source": [
        "_pytorch_ mette a disposizione un sotto-modulo, _torch.cuda_, che fornisce metodi dedicati a fare questi controlli.\n",
        "\n",
        "Rif: [torch.cuda](https://pytorch.org/docs/stable/cuda.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAF5SvygFcyb"
      },
      "source": [
        "Per prima cosa controlliamo se un device abilitato ad usare CUDA e' presente. Per farlo utilizziamo il metodo **is_available** che con un valore booleano ci restituisce questa informazione.\n",
        "\n",
        "Rif: [is_available](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5MUGuJuFcyb",
        "outputId": "202188e7-9b6f-483f-d681-b643fb7fcba6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swVQuSsHFcyc"
      },
      "source": [
        "Possono essere presenti anche piu' device abilitati nel sistema. Per sapere quanti, il metodo **device_count** ci viene in aiuto.\n",
        "\n",
        "Rif: [device_count](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrbcfSv4Fcyc",
        "outputId": "facced12-5ead-42aa-b153-f85aa12e1f63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPr2of4qFcyc"
      },
      "source": [
        "## _Un tensore, puo' essere quindi spostato su di un altro device disponibile._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBJUjLXdFcyc"
      },
      "source": [
        "Per farlo si ha a disposizione il metodo _to_ della classe **torch.Tensor**. A questo puo' essere specificato il device ed eventualmente anche l'indice.\n",
        "\n",
        "Rif: [to](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAWWpWifFcyc",
        "outputId": "14b87a28-8dce-40ca-b209-0c14b9cdd8a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****\n",
            "Valore:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]], device='cuda:0')\n",
            "\n",
            "Tipo pytohn\t: <class 'torch.Tensor'>\n",
            "Tipo\t\t: torch.int64\n",
            "Dimensioni\t: 2\n",
            "Forma\t\t: torch.Size([3, 2])\n",
            "Dispositivo\t: cuda:0\n",
            "*****\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample_tensor_gpu = sample_tensor.to(\"cuda\")\n",
        "info(sample_tensor_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXOv4LlSFcyc"
      },
      "source": [
        "Possiamo fare lo stesso, specificando anche l'indice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HEqPdYJFcyc",
        "outputId": "a7cfbc13-0003-4d78-bb5d-49996a3cb163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****\n",
            "Valore:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]], device='cuda:0')\n",
            "\n",
            "Tipo pytohn\t: <class 'torch.Tensor'>\n",
            "Tipo\t\t: torch.int64\n",
            "Dimensioni\t: 2\n",
            "Forma\t\t: torch.Size([3, 2])\n",
            "Dispositivo\t: cuda:0\n",
            "*****\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample_tensor_gpu_2 = sample_tensor.to(\"cuda:0\")\n",
        "info(sample_tensor_gpu_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrB9r10KFcyc"
      },
      "source": [
        "Riportarlo su cpu e' altrettanto semplice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyuKReReFcyc",
        "outputId": "8ce09531-2e95-4575-a351-1fb6ee4afe4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****\n",
            "Valore:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "Tipo pytohn\t: <class 'torch.Tensor'>\n",
            "Tipo\t\t: torch.int64\n",
            "Dimensioni\t: 2\n",
            "Forma\t\t: torch.Size([3, 2])\n",
            "Dispositivo\t: cpu\n",
            "*****\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample_tensor_cpu = sample_tensor_gpu.to(\"cpu\")\n",
        "info(sample_tensor_cpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZzTIivuFcyc"
      },
      "source": [
        "## _Numpy non supporta la gpu quindi il passaggio da tensore a numpy array e' invalido se il tensore sta su gpu._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR73YAG3Fcyc"
      },
      "source": [
        "Il seguente codice, se eseguito, produrra' errore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zlFdJangFcyd"
      },
      "outputs": [],
      "source": [
        "# sample_tensor_numpy = sample_tensor_gpu.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV57MNBtFcyd"
      },
      "source": [
        "Riportare il tensore su cpu prima della conversione risolvera' il problema. Per ottenere una copia del tensore spostato in memoria cpu e' possibile utilizzare il metodo _cpu_ sul tensore stesso.\n",
        "\n",
        "Rif: [cpu](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X0Rrx1s-Fcyd"
      },
      "outputs": [],
      "source": [
        "sample_tensor_numpy = sample_tensor_gpu.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbi0VVMeFcyd"
      },
      "source": [
        "## _I tensori possono venire creati, direttamente, su di un dispositivo CUDA abilitato._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLQxSnGyFcyd"
      },
      "source": [
        "Ne possiamo vedere un esempio aggiungendo il parametro _device_ durante la creazione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEXbFVl_Fcyd",
        "outputId": "295db6f5-f05b-4f76-ab52-a001327db9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****\n",
            "Valore:\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]], device='cuda:0')\n",
            "\n",
            "Tipo pytohn\t: <class 'torch.Tensor'>\n",
            "Tipo\t\t: torch.int64\n",
            "Dimensioni\t: 2\n",
            "Forma\t\t: torch.Size([3, 2])\n",
            "Dispositivo\t: cuda:0\n",
            "*****\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample_tensor = torch.tensor([[1, 2], [3, 4], [5, 6]], device=\"cuda\")\n",
        "info(sample_tensor)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "55b72797edd57f58696da9ac5b5536b8813fefe094e8c8c02c797501a07dae2a"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}